{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DATA_140 = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(stop_words, lemmatization, negation):\n",
    "    \"\"\"\n",
    "    Chargement de la base Sentiment140 et des tweets webscrapés\n",
    "    \"\"\"\n",
    "    file = \"train\"\n",
    "    if stop_words:\n",
    "        file += \"_stop\"\n",
    "    if lemmatization:\n",
    "        file += \"_lemm\"\n",
    "    if negation:\n",
    "        file += \"_neg\"\n",
    "    df_140 = pd.read_pickle(os.path.join(\"data\", \"sentiment140\", file + \".bz2\")).sample(NB_DATA_140, random_state=1234).reset_index(drop=True)\n",
    "\n",
    "    file = \"web\"\n",
    "    if stop_words:\n",
    "        file += \"_stop\"\n",
    "    if lemmatization:\n",
    "        file += \"_lemm\"\n",
    "    if negation:\n",
    "        file += \"_neg\"\n",
    "    df_web = pd.read_pickle(os.path.join(\"data\", \"web\", file + \".bz2\"))\n",
    "\n",
    "    X_140 = df_140.text.to_list()\n",
    "    y_140 = df_140.sentiment.to_list()\n",
    "\n",
    "    X_web = df_web.Text.to_list()\n",
    "    \n",
    "    return X_140, y_140, X_web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelisation():\n",
    "    def __init__(self, X_labeled, y_labeled, X_unlabeled, X_unlabeled_cat, y_unlabeled_cat, vectorizer, model, scaling=True):\n",
    "        vectorizer.fit(X_labeled + X_unlabeled)\n",
    "        X_labeled = vectorizer.transform(X_labeled)\n",
    "\n",
    "        if scaling:\n",
    "            scaler = StandardScaler(with_mean=False)\n",
    "            X_labeled = scaler.fit_transform(X_labeled)\n",
    "\n",
    "        X_train_labeled, X_test_labeled, y_train_labeled, y_test_labeled = train_test_split(X_labeled, y_labeled, train_size=0.80, random_state=1234)\n",
    "\n",
    "        model.fit(X_train_labeled, y_train_labeled)    \n",
    "        y_pred_labeled = model.predict(X_test_labeled)\n",
    "\n",
    "        X_unlabeled_cat = vectorizer.transform(X_unlabeled_cat)\n",
    "        if scaling:\n",
    "            X_unlabeled_cat = scaler.transform(X_unlabeled_cat)\n",
    "        y_pred_unlabeled_cat = model.predict(X_unlabeled_cat)\n",
    "        \n",
    "        self.X_test_labeled = X_test_labeled\n",
    "        self.y_test_labeled = y_test_labeled\n",
    "        self.y_pred_labeled = y_pred_labeled\n",
    "        self.X_unlabeled_cat = X_unlabeled_cat\n",
    "        self.y_unlabeled_cat = y_unlabeled_cat\n",
    "        self.y_pred_unlabeled_cat = y_pred_unlabeled_cat\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = model\n",
    "        self.scaling = scaling\n",
    "        \n",
    "        if scaling:\n",
    "            self.scaler = scaler\n",
    "    \n",
    "    def get_data(self):\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "    \n",
    "    def show_conf_matrix(self, X_test, y_test, y_pred):\n",
    "        metrics.plot_confusion_matrix(self.model, X_test, y_test, cmap='Blues')\n",
    "        plt.show()\n",
    "        \n",
    "        sc_accuracy = metrics.accuracy_score(y_pred, y_test)    \n",
    "        sc_balanced_accuracy = metrics.balanced_accuracy_score(y_pred, y_test)        \n",
    "        sc_roc_auc = metrics.roc_auc_score(y_test, self.model.predict_proba(X_test)[:, 1])        \n",
    "\n",
    "        print(f\"Accuracy : {sc_accuracy:.4f}\")\n",
    "        print(f\"Balanced accuracy : {sc_balanced_accuracy:.4f}\")\n",
    "        print(f\"ROC AUC : {sc_roc_auc:.4f}\")\n",
    "        \n",
    "    def show_conf_matrix_labeled(self):\n",
    "        print(\"\\nDonnées labellisées de test (Sentiment140)\")\n",
    "        self.show_conf_matrix(self.X_test_labeled, self.y_test_labeled, self.y_pred_labeled)\n",
    "        \n",
    "    def show_conf_matrix_unlabeled(self):\n",
    "        print(\"\\nDonnées non labellisées (Webscraping labellisé à la main)\")\n",
    "        self.show_conf_matrix(self.X_unlabeled_cat, self.y_unlabeled_cat, self.y_pred_unlabeled_cat)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.vectorizer.transform(X)\n",
    "        if self.scaling:\n",
    "            X = self.scaler.transform(X)\n",
    "        return self.model.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
